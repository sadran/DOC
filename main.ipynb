{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e90c7b",
   "metadata": {},
   "source": [
    "Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1eb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, yaml\n",
    "from experiments.base_experiment import BaseExperiment\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c964727",
   "metadata": {},
   "source": [
    "ExperimentFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0c2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ImageNetMobileViTExperiment.\n",
      "Using NVIDIA GeForce RTX 4090 for evaluation.\n",
      "Created the model: MobileViT(\n",
      "  (model): ByobNet(\n",
      "    (stem): ConvNormAct(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNormAct2d(\n",
      "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (drop): Identity()\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): MobileVitBlock(\n",
      "          (conv_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (transformer): Sequential(\n",
      "            (0): Block(\n",
      "              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (1): Block(\n",
      "              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv_proj): ConvNormAct(\n",
      "            (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_fusion): ConvNormAct(\n",
      "            (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): MobileVitBlock(\n",
      "          (conv_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_1x1): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (transformer): Sequential(\n",
      "            (0): Block(\n",
      "              (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=80, out_features=80, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (1): Block(\n",
      "              (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=80, out_features=80, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (2): Block(\n",
      "              (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=80, out_features=80, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (3): Block(\n",
      "              (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=80, out_features=80, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv_proj): ConvNormAct(\n",
      "            (conv): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_fusion): ConvNormAct(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): MobileVitBlock(\n",
      "          (conv_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_1x1): Conv2d(80, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (transformer): Sequential(\n",
      "            (0): Block(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (1): Block(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (2): Block(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (q_norm): Identity()\n",
      "                (k_norm): Identity()\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls1): Identity()\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
      "                (act): SiLU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (ls2): Identity()\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv_proj): ConvNormAct(\n",
      "            (conv): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_fusion): ConvNormAct(\n",
      "            (conv): Conv2d(160, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): ConvNormAct(\n",
      "      (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNormAct2d(\n",
      "        320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (drop): Identity()\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (head): ClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): Linear(in_features=320, out_features=2, bias=True)\n",
      "      (flatten): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Model parameter count: 951666\n",
      "Loaded test dataset with 600 samples from ImageNet1k dataset.\n",
      "Created test DataLoader.\n",
      "Initializing ImageNetMobileViTExperiment completed.\n"
     ]
    }
   ],
   "source": [
    "config_path = \"configs/imagenet_config.yaml\"\n",
    "\n",
    "class ExperimentFactory:\n",
    "    @staticmethod\n",
    "    def create_experiment(config) -> BaseExperiment:\n",
    "        # create and return the corresponding experiment instance based on config\n",
    "        experiment_type = config['experiment']['type']\n",
    "        if experiment_type == 'gaussian_classification':\n",
    "            from experiments.gaussian_mlp_experiment import GaussianMlpExperiment\n",
    "            return GaussianMlpExperiment(config)\n",
    "        elif experiment_type == 'mnist_classification':\n",
    "            from experiments.mnist_mlp_experiment import MnistMlpExperiment\n",
    "            return MnistMlpExperiment(config)\n",
    "        elif experiment_type == 'imagenet_classification':\n",
    "            from experiments.imagenet_mobilevit_experiment import ImageNetMobileViTExperiment\n",
    "            return ImageNetMobileViTExperiment(config)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown experiment type: {experiment_type}\")\n",
    "\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "exp = ExperimentFactory.create_experiment(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7eea99",
   "metadata": {},
   "source": [
    "**Synthetic Gaussian and MNIST datasets**\n",
    "\n",
    "***DOC & True error distribution***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5817d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating classifier density D(E) with 1000000 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 626/1000000 [01:00<26:45:57, 10.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m start_time = exp.logger.get_time_stamp()\n\u001b[32m      5\u001b[39m exp.logger.log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEstimating classifier density D(E) with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp.config[\u001b[33m'\u001b[39m\u001b[33mdoc\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mn_trials\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m true_errors = \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate_classifier_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m exp.logger.save_numpy_array(np.array(true_errors), \u001b[33m\"\u001b[39m\u001b[33mclassifier_density.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m exp.logger.log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEstimating classifier density completed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/DOC/experiments/imagenet_mobilevit_experiment.py:111\u001b[39m, in \u001b[36mImageNetMobileViTExperiment.estimate_classifier_density\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m     flat_weights =  \u001b[38;5;28mself\u001b[39m.model.sample_unit_sphere_weights(device=\u001b[38;5;28mself\u001b[39m.evaluator.device)\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.set_flatten_weights(flat_weights)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     true_error = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     true_errors.append(true_error)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m true_errors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py:121\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/DOC/core/evaluator.py:46\u001b[39m, in \u001b[36mEvaluator.compute_error\u001b[39m\u001b[34m(self, model, loader)\u001b[39m\n\u001b[32m     44\u001b[39m preds = logits.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     45\u001b[39m total = y.numel()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m incorrect = \u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m incorrect / total \u001b[38;5;28;01mif\u001b[39;00m total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 1) Estimate classifier density D(E) (left plot)\n",
    "# ---------------------------------------------\n",
    "start_time = exp.logger.get_time_stamp()\n",
    "exp.logger.log(f\"Estimating classifier density D(E) with {exp.config['doc']['n_trials']} trials.\")\n",
    "true_errors = exp.estimate_classifier_density()\n",
    "exp.logger.save_numpy_array(np.array(true_errors), \"classifier_density.npy\")\n",
    "exp.logger.log(f\"Estimating classifier density completed.\")\n",
    "hist_fig, _ = exp.plotter.plot_histogram(data=true_errors,\n",
    "                                            bins=exp.config['doc']['histogram_bins'],\n",
    "                                            title = \"Classifier Density D(E)\",\n",
    "                                            xlabel = \"E\",\n",
    "                                            ylabel = \"D(E)\")\n",
    "exp.logger.save_figure(hist_fig, \"classifier_density_histogram.png\")\n",
    "end_time = exp.logger.get_time_stamp()\n",
    "exp.logger.log(f\"Time taken for estimating classifier density: {end_time - start_time}\")\n",
    "plt.figure(hist_fig)   # activate the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644342a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 2) Estimate true-error distribution of ERM solutions (middle plot)\n",
    "# -------------------------------------------------------------------\n",
    "start_time = exp.logger.get_time_stamp()\n",
    "exp.logger.log(\"Estimating true error distribution for random weights with zero training error.\")\n",
    "solutions_true_errors = exp.estimate_true_error_distribution()\n",
    "# Save numpy array of zero empirical true errors\n",
    "exp.logger.save_numpy_array(np.array(solutions_true_errors, dtype=object), \"solutions_true_errors.npy\")\n",
    "# plot boxplot of true errors for different training set sizes\n",
    "boxplot_fig, _ = exp.plotter.plot_boxplot(true_errors=solutions_true_errors,\n",
    "                                            n_values=exp.config['erm']['n_values'],\n",
    "                                            title=\"True Error Distribution for Random Weights with Zero Training Error\",\n",
    "                                            xlabel=\"Number of Training Samples\",\n",
    "                                            ylabel=\"True Error\")\n",
    "exp.logger.save_figure(boxplot_fig, \"solutions_true_error_boxplot.png\")\n",
    "end_time = exp.logger.get_time_stamp()\n",
    "exp.logger.log(f\"Time taken for estimating true error distribution: {end_time - start_time}\")\n",
    "plt.figure(boxplot_fig)   # activate the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 3) Right-column plot (red x vs blue x)\n",
    "#     - red x: empirical mean of ERM true errors (from middle plot)\n",
    "#     - blue x: DOC-based predicted mean computed from D(E) (left plot)\n",
    "# -------------------------------------------------------------------\n",
    "start_time = exp.logger.get_time_stamp()\n",
    "exp.logger.log(\"Computing DOC-based predicted mean true error and comparing with ERM empirical means.\")\n",
    "# Red crosses: empirical mean test error for each n\n",
    "erm_means = np.array([float(np.mean(errs)) for errs in solutions_true_errors], dtype=float)\n",
    "# Blue crosses: DOC prediction from D(E)\n",
    "doc_means = exp.doc_predicted_mean_error(true_errors)\n",
    "# Plot comparison (right-column figure)\n",
    "doc_vs_erm_fig, ax = exp.plotter.plot_doc_vs_erm(exp.config['erm']['n_values'], erm_means, doc_means)\n",
    "exp.logger.save_figure(doc_vs_erm_fig, \"doc_vs_erm_mean_true_error.png\")\n",
    "end_time = exp.logger.get_time_stamp()\n",
    "exp.logger.log(f\"Time taken for computing DOC vs ERM comparison: {end_time - start_time}\")\n",
    "plt.figure(doc_vs_erm_fig)   # activate the figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
